{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('spam_train.csv')\n",
    "test = pd.read_csv('spam_test.csv')\n",
    "## separate the predictors and response in the training data set\n",
    "x_train = np.array(train.iloc[:, 0:57])\n",
    "y_train = np.ravel(train.iloc[:, -1])\n",
    "## separate the predictors and response in the test data set\n",
    "x_test = np.array(test.iloc[:, 0:57])\n",
    "y_test = np.ravel(test.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A.1</th>\n",
       "      <th>A.2</th>\n",
       "      <th>A.3</th>\n",
       "      <th>A.4</th>\n",
       "      <th>A.5</th>\n",
       "      <th>A.6</th>\n",
       "      <th>A.7</th>\n",
       "      <th>A.8</th>\n",
       "      <th>A.9</th>\n",
       "      <th>A.10</th>\n",
       "      <th>...</th>\n",
       "      <th>A.49</th>\n",
       "      <th>A.50</th>\n",
       "      <th>A.51</th>\n",
       "      <th>A.52</th>\n",
       "      <th>A.53</th>\n",
       "      <th>A.54</th>\n",
       "      <th>A.55</th>\n",
       "      <th>A.56</th>\n",
       "      <th>A.57</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.068</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.685</td>\n",
       "      <td>7</td>\n",
       "      <td>204</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.424</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A.1  A.2   A.3  A.4   A.5   A.6  A.7  A.8  A.9  A.10  ...    A.49   A.50  \\\n",
       "0  0.32  0.0  0.00  0.0  0.32  0.00  0.0  0.0  0.0   0.0  ...     0.0  0.234   \n",
       "1  0.00  0.0  0.71  0.0  0.00  0.00  0.0  0.0  0.0   0.0  ...     0.0  0.000   \n",
       "2  0.00  0.0  0.00  0.0  0.00  0.17  0.0  0.0  0.0   0.0  ...     0.0  0.055   \n",
       "3  0.00  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.0   0.0  ...     0.0  0.000   \n",
       "4  0.00  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.0   0.0  ...     0.0  0.471   \n",
       "\n",
       "   A.51   A.52  A.53  A.54   A.55  A.56  A.57   spam  \n",
       "0   0.0  0.058   0.0   0.0  1.068     3    47  email  \n",
       "1   0.0  0.342   0.0   0.0  1.000     1    31  email  \n",
       "2   0.0  0.000   0.0   0.0  1.685     7   204  email  \n",
       "3   0.0  0.000   0.0   0.0  1.800     5     9  email  \n",
       "4   0.0  0.000   0.0   0.0  1.424     8    47  email  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2300, 58)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2301, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.00043\n",
      "The test     error is: 0.09952\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "tree_model.fit(x_train, y_train)\n",
    "print \"The training error is: %.5f\" %(1-tree_model.score(x_train, y_train))\n",
    "print \"The test     error is: %.5f\" %(1-tree_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('A.53', 0.3223766329367802), ('A.7', 0.17003175360850453),\n",
       "       ('A.52', 0.0861158411727707), ('A.25', 0.06949770067234269),\n",
       "       ('A.55', 0.032378510343003535), ('A.16', 0.02773903333673073),\n",
       "       ('A.56', 0.026548183523085658), ('A.19', 0.018803019378488963),\n",
       "       ('A.46', 0.018451639879318384), ('A.5', 0.01544331796131112),\n",
       "       ('A.21', 0.014932962411667769), ('A.10', 0.01339397804379201),\n",
       "       ('A.45', 0.013376660973317477), ('A.50', 0.013040331239923743),\n",
       "       ('A.39', 0.012071304419586803), ('A.8', 0.010344206207894861),\n",
       "       ('A.24', 0.009440320248195622), ('A.18', 0.007669482658742127),\n",
       "       ('A.11', 0.0072037024447399855), ('A.23', 0.006840015592416773),\n",
       "       ('A.17', 0.005436107978309906), ('A.42', 0.0051702917730658765),\n",
       "       ('A.49', 0.003950160964490621), ('A.27', 0.0037540659269403834),\n",
       "       ('A.43', 0.0035612229405218372), ('A.51', 0.0034970675921820356),\n",
       "       ('A.1', 0.003089068311404876), ('A.9', 0.002981358416172833),\n",
       "       ('A.12', 0.0027722524200614806), ('A.28', 0.0025708573274388696),\n",
       "       ('A.6', 0.0025525367294009635), ('A.37', 0.0024050495071172634),\n",
       "       ('A.36', 0.0023664224616846666), ('A.32', 0.0021831487807984153),\n",
       "       ('A.29', 0.0017508838696728313), ('A.2', 0.001633328675289454),\n",
       "       ('A.54', 0.0014375692341902651), ('A.47', 0.0012128604337768975),\n",
       "       ('A.14', 0.000549749172933457), ('A.20', 0.0005288115834555542),\n",
       "       ('A.48', 0.0), ('A.44', 0.0), ('A.41', 0.0), ('A.40', 0.0),\n",
       "       ('A.4', 0.0), ('A.38', 0.0), ('A.35', 0.0), ('A.34', 0.0),\n",
       "       ('A.33', 0.0), ('A.31', 0.0), ('A.30', 0.0), ('A.3', 0.0),\n",
       "       ('A.26', 0.0), ('A.22', 0.0), ('A.15', 0.0), ('A.13', 0.0)], \n",
       "      dtype=[('feature', 'S10'), ('importance', '<f8')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imprtance = zip(train.columns[:-2], tree_model.feature_importances_)\n",
    "dtype = [('feature', 'S10'), ('importance', 'float')]\n",
    "feature_imprtance = np.array(feature_imprtance, dtype = dtype)\n",
    "feature_sort = np.sort(feature_imprtance, order='importance')[::-1]\n",
    "feature_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search\n",
    "# min_samples_split: The minimum number of samples required to split an internal node:\n",
    "# min_samples_leaf:The minimum number of samples required to be at a leaf node\n",
    "import sklearn.grid_search as gs\n",
    "np.random.seed(108)\n",
    "grid_para_tree = [{\"criterion\": [\"gini\", \"entropy\"], \"min_samples_leaf\": range(1, 10),\n",
    "                   \"min_samples_split\": range(2, 30, 2)}]\n",
    "grid_search_tree = gs.GridSearchCV(tree_model, grid_para_tree, cv=5,\n",
    "                                   scoring='accuracy')\n",
    "grid_search_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'min_samples_leaf': 2, 'min_samples_split': 28}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## best parameter\n",
    "grid_search_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9143478260869565"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## best score\n",
    "grid_search_tree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:438: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95739130434782604"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The overall accuracy on the training set:\n",
    "grid_search_tree.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90830073880921336"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The overall accuracy on the test set:\n",
    "grid_search_tree.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "randomForest = ensemble.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of random forest is: 0.00043\n",
      "The test     error of random forest is: 0.05780\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "randomForest.set_params(n_estimators=50)\n",
    "randomForest.fit(x_train, y_train)\n",
    "print \"The training error of random forest is: %.5f\" %(1-randomForest.score(x_train, y_train))\n",
    "print \"The test     error of random forest is: %.5f\" %(1-randomForest.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('A.52', 0.13703054014879038), ('A.53', 0.10138275637238126),\n",
       "       ('A.55', 0.080019529879591), ('A.7', 0.07750593621455441),\n",
       "       ('A.21', 0.053417504303190234), ('A.16', 0.04871844276061167),\n",
       "       ('A.56', 0.046098576895094265), ('A.25', 0.04030202822924379),\n",
       "       ('A.24', 0.03686407569353951), ('A.5', 0.03659687451362182),\n",
       "       ('A.19', 0.027636190695141755), ('A.23', 0.017168691881403884),\n",
       "       ('A.27', 0.01650388530054146), ('A.17', 0.0148649834599953),\n",
       "       ('A.46', 0.014123461853311165), ('A.11', 0.013884966143222854),\n",
       "       ('A.26', 0.013415530018130999), ('A.50', 0.012216009377617347),\n",
       "       ('A.8', 0.011701511500561), ('A.37', 0.011197826428211767),\n",
       "       ('A.12', 0.010480104050571036), ('A.18', 0.009621385996535734),\n",
       "       ('A.45', 0.009262299436612014), ('A.3', 0.008674586950899718),\n",
       "       ('A.10', 0.008143663033822145), ('A.6', 0.007181492386500117),\n",
       "       ('A.28', 0.005834877341539431), ('A.49', 0.005789253991879822),\n",
       "       ('A.35', 0.005715997019524488), ('A.36', 0.005321966755728036),\n",
       "       ('A.13', 0.005037134146951399), ('A.42', 0.004890592387446118),\n",
       "       ('A.39', 0.004617011203597646), ('A.2', 0.004544521438679969),\n",
       "       ('A.1', 0.004183603338326448), ('A.9', 0.003929641543384822),\n",
       "       ('A.51', 0.003684888186455607), ('A.33', 0.003103902211793042),\n",
       "       ('A.20', 0.0026799045975133577), ('A.54', 0.002604455998898988),\n",
       "       ('A.43', 0.002600490322265721), ('A.22', 0.0023792600232429694),\n",
       "       ('A.30', 0.0023728286448472372), ('A.44', 0.0018458283260784421),\n",
       "       ('A.31', 0.0016217436756334998), ('A.40', 0.0014512669670718452),\n",
       "       ('A.29', 0.0014394958495264525), ('A.15', 0.0012729715466662658),\n",
       "       ('A.38', 0.0011250741864323528), ('A.41', 0.0010972003180688642),\n",
       "       ('A.14', 0.0010741101390890542), ('A.34', 0.0008094506530030672),\n",
       "       ('A.48', 0.0004993668091753489), ('A.32', 0.00047311127177493114),\n",
       "       ('A.4', 0.00033241850835461466), ('A.47', 0.00010415289248312408)], \n",
       "      dtype=[('feature', 'S10'), ('importance', '<f8')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imprtance = zip(train.columns[:-2], randomForest.feature_importances_)\n",
    "dtype = [('feature', 'S10'), ('importance', 'float')]\n",
    "feature_imprtance = np.array(feature_imprtance, dtype = dtype)\n",
    "feature_sort = np.sort(feature_imprtance, order='importance')[::-1]\n",
    "feature_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 50, 100], 'min_samples_split': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28], 'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "# max_feature: feature considered for splitting\n",
    "# n_estimators: number of tree\n",
    "# min_samples_split: The minimum number of samples required to split an internal node:\n",
    "# min_samples_leaf: The minimum number of samples required to be at a leaf node\n",
    "\n",
    "grid_para_forest = [{\"n_estimators\": [10, 50, 100], \"criterion\": [\"gini\", \"entropy\"], \\\n",
    "                    \"min_samples_leaf\": range(1, 10), \"min_samples_split\": range(2, 30, 2)}]\n",
    "grid_search_forest = gs.GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5)\n",
    "grid_search_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469565217391305"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is: 0.00696\n",
      "The test     error is: 0.05693\n"
     ]
    }
   ],
   "source": [
    "print \"The training error is: %.5f\"%(1-grid_search_forest.score(x_train, y_train))\n",
    "print \"The test     error is: %.5f\"%(1-grid_search_forest.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of gradient boosting is: 0.04609\n",
      "The test     error of gradient boosting is: 0.06562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBM=GradientBoostingClassifier()\n",
    "np.random.seed(1)\n",
    "GBM.set_params(n_estimators=50)\n",
    "GBM.fit(x_train, y_train)\n",
    "print \"The training error of gradient boosting is: %.5f\" %(1-GBM.score(x_train, y_train))\n",
    "print \"The test     error of gradient boosting is: %.5f\" %(1-GBM.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['email', 'email', 'email', ..., 'email', 'email', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0333752 ,  0.17857711,  0.04552774, ...,  0.0943025 ,\n",
       "        0.08174416,  0.97825915])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning parameters\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def modelfit(alg, x_train, y_train, train, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(x_train, y_train)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(x_train)\n",
    "    dtrain_predprob = alg.predict_proba(x_train)[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(alg, x_train, y_train, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(y_train, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob)\n",
    "    \n",
    "    if performCV:\n",
    "        print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_,train.columns[:-1]).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train=[1 if x=='spam' else 0 for x in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9678\n",
      "AUC Score (Train): 0.995170\n",
      "CV Score : Mean - 0.9834704 | Std - 0.004705594 | Min - 0.9773105 | Max - 0.9902308\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAEXCAYAAABie7hJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1168fb690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm0 = GradientBoostingClassifier(random_state=10)\n",
    "modelfit(gbm0, x_train, Y_train, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "              min_samples_split=500, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': [20, 30, 40, 50, 60, 70, 80]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix learning rate and number of estimators for tuning tree-based parameters\n",
    "param_test1 = {'n_estimators':range(20,81,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.96913, std: 0.00599, params: {'n_estimators': 20},\n",
       "  mean: 0.97359, std: 0.00491, params: {'n_estimators': 30},\n",
       "  mean: 0.97703, std: 0.00516, params: {'n_estimators': 40},\n",
       "  mean: 0.97919, std: 0.00507, params: {'n_estimators': 50},\n",
       "  mean: 0.98148, std: 0.00473, params: {'n_estimators': 60},\n",
       "  mean: 0.98258, std: 0.00480, params: {'n_estimators': 70},\n",
       "  mean: 0.98330, std: 0.00480, params: {'n_estimators': 80}],\n",
       " {'n_estimators': 80},\n",
       " 0.9832963381633849)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best n_estimators: 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.98363, std: 0.00547, params: {'min_samples_split': 200, 'max_depth': 5},\n",
       "  mean: 0.98318, std: 0.00569, params: {'min_samples_split': 400, 'max_depth': 5},\n",
       "  mean: 0.98207, std: 0.00561, params: {'min_samples_split': 600, 'max_depth': 5},\n",
       "  mean: 0.98127, std: 0.00559, params: {'min_samples_split': 800, 'max_depth': 5},\n",
       "  mean: 0.98044, std: 0.00510, params: {'min_samples_split': 1000, 'max_depth': 5},\n",
       "  mean: 0.98426, std: 0.00556, params: {'min_samples_split': 200, 'max_depth': 7},\n",
       "  mean: 0.98370, std: 0.00560, params: {'min_samples_split': 400, 'max_depth': 7},\n",
       "  mean: 0.98295, std: 0.00530, params: {'min_samples_split': 600, 'max_depth': 7},\n",
       "  mean: 0.98193, std: 0.00572, params: {'min_samples_split': 800, 'max_depth': 7},\n",
       "  mean: 0.98031, std: 0.00532, params: {'min_samples_split': 1000, 'max_depth': 7},\n",
       "  mean: 0.98425, std: 0.00473, params: {'min_samples_split': 200, 'max_depth': 9},\n",
       "  mean: 0.98390, std: 0.00507, params: {'min_samples_split': 400, 'max_depth': 9},\n",
       "  mean: 0.98309, std: 0.00563, params: {'min_samples_split': 600, 'max_depth': 9},\n",
       "  mean: 0.98249, std: 0.00549, params: {'min_samples_split': 800, 'max_depth': 9},\n",
       "  mean: 0.98033, std: 0.00540, params: {'min_samples_split': 1000, 'max_depth': 9},\n",
       "  mean: 0.98529, std: 0.00501, params: {'min_samples_split': 200, 'max_depth': 11},\n",
       "  mean: 0.98453, std: 0.00467, params: {'min_samples_split': 400, 'max_depth': 11},\n",
       "  mean: 0.98339, std: 0.00532, params: {'min_samples_split': 600, 'max_depth': 11},\n",
       "  mean: 0.98213, std: 0.00553, params: {'min_samples_split': 800, 'max_depth': 11},\n",
       "  mean: 0.98035, std: 0.00524, params: {'min_samples_split': 1000, 'max_depth': 11},\n",
       "  mean: 0.98458, std: 0.00492, params: {'min_samples_split': 200, 'max_depth': 13},\n",
       "  mean: 0.98382, std: 0.00541, params: {'min_samples_split': 400, 'max_depth': 13},\n",
       "  mean: 0.98348, std: 0.00560, params: {'min_samples_split': 600, 'max_depth': 13},\n",
       "  mean: 0.98196, std: 0.00580, params: {'min_samples_split': 800, 'max_depth': 13},\n",
       "  mean: 0.98032, std: 0.00524, params: {'min_samples_split': 1000, 'max_depth': 13},\n",
       "  mean: 0.98555, std: 0.00411, params: {'min_samples_split': 200, 'max_depth': 15},\n",
       "  mean: 0.98451, std: 0.00513, params: {'min_samples_split': 400, 'max_depth': 15},\n",
       "  mean: 0.98392, std: 0.00536, params: {'min_samples_split': 600, 'max_depth': 15},\n",
       "  mean: 0.98185, std: 0.00562, params: {'min_samples_split': 800, 'max_depth': 15},\n",
       "  mean: 0.98032, std: 0.00524, params: {'min_samples_split': 1000, 'max_depth': 15}],\n",
       " {'max_depth': 15, 'min_samples_split': 200},\n",
       " 0.9855533269873561)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix # of trees tune max_depth, min_samples_split\n",
    "param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(x_train,Y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'n_estimators': 80, 'max_depth': 15, 'min_samples_split': 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.98505, std: 0.00555, params: {'min_samples_leaf': 10},\n",
       "  mean: 0.98555, std: 0.00523, params: {'min_samples_leaf': 12},\n",
       "  mean: 0.98610, std: 0.00506, params: {'min_samples_leaf': 14},\n",
       "  mean: 0.98577, std: 0.00549, params: {'min_samples_leaf': 16},\n",
       "  mean: 0.98571, std: 0.00496, params: {'min_samples_leaf': 18},\n",
       "  mean: 0.98564, std: 0.00498, params: {'min_samples_leaf': 20},\n",
       "  mean: 0.98502, std: 0.00536, params: {'min_samples_leaf': 22},\n",
       "  mean: 0.98512, std: 0.00505, params: {'min_samples_leaf': 24},\n",
       "  mean: 0.98471, std: 0.00567, params: {'min_samples_leaf': 26},\n",
       "  mean: 0.98487, std: 0.00513, params: {'min_samples_leaf': 28}],\n",
       " {'min_samples_leaf': 14},\n",
       " 0.9861003777038423)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_leaf':range(10,30,2)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80,\n",
    "                                                               max_depth=15, min_samples_split=200,\n",
    "                                                               max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(x_train, Y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.98374, std: 0.00578, params: {'max_features': 2},\n",
       "  mean: 0.98497, std: 0.00511, params: {'max_features': 3},\n",
       "  mean: 0.98543, std: 0.00545, params: {'max_features': 4},\n",
       "  mean: 0.98531, std: 0.00433, params: {'max_features': 5},\n",
       "  mean: 0.98480, std: 0.00589, params: {'max_features': 6},\n",
       "  mean: 0.98610, std: 0.00506, params: {'max_features': 7},\n",
       "  mean: 0.98517, std: 0.00521, params: {'max_features': 8},\n",
       "  mean: 0.98530, std: 0.00519, params: {'max_features': 9},\n",
       "  mean: 0.98524, std: 0.00554, params: {'max_features': 10},\n",
       "  mean: 0.98497, std: 0.00526, params: {'max_features': 11},\n",
       "  mean: 0.98525, std: 0.00524, params: {'max_features': 12},\n",
       "  mean: 0.98512, std: 0.00553, params: {'max_features': 13},\n",
       "  mean: 0.98481, std: 0.00514, params: {'max_features': 14},\n",
       "  mean: 0.98536, std: 0.00537, params: {'max_features': 15},\n",
       "  mean: 0.98550, std: 0.00607, params: {'max_features': 16},\n",
       "  mean: 0.98492, std: 0.00528, params: {'max_features': 17},\n",
       "  mean: 0.98505, std: 0.00503, params: {'max_features': 18},\n",
       "  mean: 0.98469, std: 0.00565, params: {'max_features': 19}],\n",
       " {'max_features': 7},\n",
       " 0.9861003777038423)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':range(2,20,1)}\n",
    "gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80,\n",
    "                                                               max_depth=15, min_samples_split=200,\n",
    "                                                               min_samples_leaf=14, subsample=0.8, random_state=10),\n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(x_train, Y_train)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.98400, std: 0.00580, params: {'subsample': 0.6},\n",
       "  mean: 0.98523, std: 0.00506, params: {'subsample': 0.7},\n",
       "  mean: 0.98560, std: 0.00581, params: {'subsample': 0.75},\n",
       "  mean: 0.98610, std: 0.00506, params: {'subsample': 0.8},\n",
       "  mean: 0.98525, std: 0.00560, params: {'subsample': 0.85},\n",
       "  mean: 0.98544, std: 0.00474, params: {'subsample': 0.9}],\n",
       " {'subsample': 0.8},\n",
       " 0.9861003777038423)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=80,\n",
    "                                                               max_depth=15,min_samples_split=200, \n",
    "                                                               min_samples_leaf=14,random_state=10,\n",
    "                                                               max_features=7),\n",
    "param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(x_train, Y_train)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.98626, std: 0.00543, params: {'n_estimators': 100, 'learning_rate': 0.1},\n",
       "  mean: 0.98599, std: 0.00681, params: {'n_estimators': 200, 'learning_rate': 0.1},\n",
       "  mean: 0.98625, std: 0.00673, params: {'n_estimators': 300, 'learning_rate': 0.1},\n",
       "  mean: 0.98588, std: 0.00672, params: {'n_estimators': 400, 'learning_rate': 0.1},\n",
       "  mean: 0.98599, std: 0.00662, params: {'n_estimators': 500, 'learning_rate': 0.1},\n",
       "  mean: 0.98567, std: 0.00686, params: {'n_estimators': 600, 'learning_rate': 0.1},\n",
       "  mean: 0.98580, std: 0.00676, params: {'n_estimators': 700, 'learning_rate': 0.1},\n",
       "  mean: 0.98580, std: 0.00673, params: {'n_estimators': 800, 'learning_rate': 0.1},\n",
       "  mean: 0.98569, std: 0.00670, params: {'n_estimators': 900, 'learning_rate': 0.1},\n",
       "  mean: 0.98464, std: 0.00466, params: {'n_estimators': 100, 'learning_rate': 0.05},\n",
       "  mean: 0.98618, std: 0.00511, params: {'n_estimators': 200, 'learning_rate': 0.05},\n",
       "  mean: 0.98657, std: 0.00538, params: {'n_estimators': 300, 'learning_rate': 0.05},\n",
       "  mean: 0.98654, std: 0.00552, params: {'n_estimators': 400, 'learning_rate': 0.05},\n",
       "  mean: 0.98674, std: 0.00562, params: {'n_estimators': 500, 'learning_rate': 0.05},\n",
       "  mean: 0.98645, std: 0.00581, params: {'n_estimators': 600, 'learning_rate': 0.05},\n",
       "  mean: 0.98636, std: 0.00592, params: {'n_estimators': 700, 'learning_rate': 0.05},\n",
       "  mean: 0.98626, std: 0.00597, params: {'n_estimators': 800, 'learning_rate': 0.05},\n",
       "  mean: 0.98623, std: 0.00602, params: {'n_estimators': 900, 'learning_rate': 0.05},\n",
       "  mean: 0.97486, std: 0.00585, params: {'n_estimators': 100, 'learning_rate': 0.01},\n",
       "  mean: 0.97830, std: 0.00534, params: {'n_estimators': 200, 'learning_rate': 0.01},\n",
       "  mean: 0.98126, std: 0.00517, params: {'n_estimators': 300, 'learning_rate': 0.01},\n",
       "  mean: 0.98307, std: 0.00517, params: {'n_estimators': 400, 'learning_rate': 0.01},\n",
       "  mean: 0.98456, std: 0.00500, params: {'n_estimators': 500, 'learning_rate': 0.01},\n",
       "  mean: 0.98537, std: 0.00505, params: {'n_estimators': 600, 'learning_rate': 0.01},\n",
       "  mean: 0.98587, std: 0.00506, params: {'n_estimators': 700, 'learning_rate': 0.01},\n",
       "  mean: 0.98615, std: 0.00509, params: {'n_estimators': 800, 'learning_rate': 0.01},\n",
       "  mean: 0.98638, std: 0.00512, params: {'n_estimators': 900, 'learning_rate': 0.01}],\n",
       " {'learning_rate': 0.05, 'n_estimators': 500},\n",
       " 0.9867352862466721)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# increase trees and decrease learning rate\n",
    "param_test6 = {'n_estimators':range(100,1000,100), 'learning_rate': [0.1, 0.05, 0.01]}\n",
    "gsearch6 = GridSearchCV(estimator = GradientBoostingClassifier(max_depth=15,min_samples_split=200, \n",
    "                                                               min_samples_leaf=14, subsample=0.8, \n",
    "                                                               random_state=10,max_features=7),\n",
    "param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(x_train, Y_train)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of gradient boosting is: 0.00043\n",
      "The test     error of gradient boosting is: 0.05346\n"
     ]
    }
   ],
   "source": [
    "# max_depth=15,min_samples_split=200, min_samples_leaf=14, subsample=0.8, \n",
    "# max_features=7, learning_rate=0.05, n_estimators=500\n",
    "np.random.seed(1)\n",
    "GBM.set_params(max_depth=15,min_samples_split=200, min_samples_leaf=14, subsample=0.8, \n",
    "               max_features=7, learning_rate=0.05, n_estimators=500)\n",
    "GBM.fit(x_train, y_train)\n",
    "print \"The training error of gradient boosting is: %.5f\" %(1-GBM.score(x_train, y_train))\n",
    "print \"The test     error of gradient boosting is: %.5f\" %(1-GBM.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of Xgboost is: 0.04913\n",
      "The test     error of Xgboost is: 0.06475\n"
     ]
    }
   ],
   "source": [
    "XGB=XGBClassifier()\n",
    "np.random.seed(1)\n",
    "XGB.set_params(n_estimators=50)\n",
    "XGB.fit(x_train, y_train)\n",
    "print \"The training error of Xgboost is: %.5f\" %(1-XGB.score(x_train, y_train))\n",
    "print \"The test     error of Xgboost is: %.5f\" %(1-XGB.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:52: DeprecationWarning: Class GaussianProcess is deprecated; GaussianProcess was deprecated in version 0.18 and will be removed in 0.20. Use the GaussianProcessRegressor instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   learning_rate |   max_depth |   min_child_weight |   n_estimators |   subsample | \n",
      "    1 | 00m08s | \u001b[35m   0.98095\u001b[0m | \u001b[32m            0.9061\u001b[0m | \u001b[32m   0.5495\u001b[0m | \u001b[32m         0.0219\u001b[0m | \u001b[32m    15.4459\u001b[0m | \u001b[32m            9.4954\u001b[0m | \u001b[32m      245.1318\u001b[0m | \u001b[32m     0.8460\u001b[0m | \n",
      "    2 | 00m03s | \u001b[35m   0.98172\u001b[0m | \u001b[32m            0.6183\u001b[0m | \u001b[32m   0.2535\u001b[0m | \u001b[32m         0.1282\u001b[0m | \u001b[32m    15.7550\u001b[0m | \u001b[32m            4.1289\u001b[0m | \u001b[32m      174.7521\u001b[0m | \u001b[32m     0.5918\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   learning_rate |   max_depth |   min_child_weight |   n_estimators |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3 | 00m14s |    0.98140 |             0.8876 |    1.0000 |          0.0515 |     10.8683 |             4.5283 |       400.1451 |      0.6559 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 | 00m12s | \u001b[35m   0.98244\u001b[0m | \u001b[32m            0.8956\u001b[0m | \u001b[32m   1.0000\u001b[0m | \u001b[32m         0.0253\u001b[0m | \u001b[32m     6.2886\u001b[0m | \u001b[32m            5.6463\u001b[0m | \u001b[32m      439.4375\u001b[0m | \u001b[32m     0.7717\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 | 00m08s |    0.98085 |             0.5754 |    1.0000 |          0.0358 |     17.3394 |             9.9592 |       429.2856 |      0.8402 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 | 00m11s | \u001b[35m   0.98523\u001b[0m | \u001b[32m            0.6737\u001b[0m | \u001b[32m   1.0000\u001b[0m | \u001b[32m         0.0980\u001b[0m | \u001b[32m    19.1974\u001b[0m | \u001b[32m            1.5356\u001b[0m | \u001b[32m      270.6310\u001b[0m | \u001b[32m     0.9611\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7 | 00m04s |    0.97808 |             0.8709 |    1.0000 |          0.1905 |      9.9725 |             5.1683 |       124.0703 |      0.5247 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 | 00m03s |    0.97997 |             0.6769 |    1.0000 |          0.0527 |     14.1951 |             8.1816 |        90.2037 |      0.7267 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9 | 00m04s |    0.98067 |             0.5666 |    1.0000 |          0.1735 |      5.3238 |             7.4385 |       221.1751 |      0.9438 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 | 00m05s |    0.96312 |             0.9053 |    1.0000 |          0.0107 |     15.5152 |             6.1795 |        98.8002 |      0.5130 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 00m04s |    0.97928 |             0.7479 |    1.0000 |          0.0384 |      5.3582 |             7.5829 |       155.4392 |      0.5955 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function l1_cross_distances is deprecated; l1_cross_distances was deprecated in version 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 00m04s |    0.98126 |             0.6047 |    1.0000 |          0.1593 |      3.8891 |             3.6568 |       324.8189 |      0.7097 | \n",
      "-----------------------------------------------------\n",
      "Final Results\n",
      "XGBOOST: 0.985226\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from bayes_opt import bayesian_optimization\n",
    "import sklearn.cross_validation as cv\n",
    "def xgboostcv(max_depth,\n",
    "              learning_rate,\n",
    "              n_estimators,\n",
    "              gamma,\n",
    "              min_child_weight,\n",
    "              subsample,\n",
    "              colsample_bytree,\n",
    "              silent=True,\n",
    "              nthread=-1):\n",
    "    return cross_val_score(xgb.XGBClassifier(max_depth=int(max_depth),\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            n_estimators=int(n_estimators),\n",
    "                                            silent=silent,\n",
    "                                            nthread=nthread,\n",
    "                                            gamma=gamma,\n",
    "                                            min_child_weight=min_child_weight,\n",
    "                                            subsample=subsample,\n",
    "                                            colsample_bytree=colsample_bytree),\n",
    "                           x_train,\n",
    "                           Y_train,\n",
    "                           'roc_auc',\n",
    "                           cv=5).mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    xgboostBO = bayesian_optimization.BayesianOptimization(xgboostcv,\n",
    "                                 {'max_depth': (3, 20),\n",
    "                                  'learning_rate': (0.01, 0.2),\n",
    "                                  'n_estimators': (50, 500),\n",
    "                                  'gamma': (1., 0.01),\n",
    "                                  'min_child_weight': (1, 10),\n",
    "                                  'subsample': (0.5, 1),\n",
    "                                  'colsample_bytree' :(0.5, 1)})\n",
    "    xgboostBO.maximize(init_points=2, n_iter = 10)\n",
    "    print('-'*53)\n",
    "    print('Final Results')\n",
    "    print('XGBOOST: %f' % xgboostBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0034782608695652639"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "XGB.set_params(max_depth=19,learning_rate=0.0980,n_estimators=270,silent=True,nthread=-1,gamma=1,min_child_weight=1.5356,\n",
    "               subsample=0.9611,colsample_bytree=0.6737)\n",
    "XGB.fit(x_train, y_train)\n",
    "1-XGB.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052585832246849207"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-XGB.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
